{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import keras\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Embedding, Dense, Flatten, BatchNormalization\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.merge import Add\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.optimizers import RMSprop, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600893\n"
     ]
    }
   ],
   "source": [
    "path = get_file('nietzsche.txt', origin=\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\")\n",
    "text = open(path).read()\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size: 85\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\x00\\n !\"\\'(),-.0123456789:;=?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_abcdefghijklmnopqrstuvwxyzÆäæéë'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "# Sometimes it's useful to have a zero value in the dataset, e.g. for padding\n",
    "chars.insert(0, '\\0')\n",
    "vocab_size = len(chars)\n",
    "\n",
    "print('vocab size:', vocab_size)\n",
    "''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_to_idx = dict((c, i) for i, c in enumerate(chars))\n",
    "idx_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = [char_to_idx[c] for c in text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 根据3个char 得到第4个char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clen = 3\n",
    "\n",
    "c1_data = [idx[i] for i in range(0, len(idx)-clen-1, clen)] # 这里的间距调成1应该也是没问题的\n",
    "c2_data = [idx[i+1] for i in range(0, len(idx)-clen-1, clen)]\n",
    "c3_data = [idx[i+2] for i in range(0, len(idx)-clen-1, clen)]\n",
    "c4_data = [idx[i+3] for i in range(0, len(idx)-clen-1, clen)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1 = np.array(c1_data)\n",
    "x2 = np.array(c2_data)\n",
    "x3 = np.array(c3_data)\n",
    "y = np.array(c4_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200297,), (200297,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "embedding layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def embedding_input(name, n_in, n_out):\n",
    "    inp = Input(shape=(1,), dtype='int64', name=name)\n",
    "    emb = Embedding(n_in, n_out, input_length=1)(inp)\n",
    "    return inp, Flatten()(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_fac = 42 # 隐藏因子数\n",
    "c1_inp, c1_emb = embedding_input('c1', vocab_size, n_fac)\n",
    "c2_inp, c2_emb = embedding_input('c2', vocab_size, n_fac)\n",
    "c3_inp, c3_emb = embedding_input('c3', vocab_size, n_fac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden = 256\n",
    "\n",
    "dense_in = Dense(n_hidden, activation='relu')\n",
    "dense_hidden = Dense(n_hidden, activation='tanh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c1_den = dense_in(c1_emb)\n",
    "\n",
    "c2_den = dense_in(c2_emb)\n",
    "hidden_2 = dense_hidden(c1_den)\n",
    "hidden_2_add = Add()([c2_den, hidden_2])\n",
    "\n",
    "c3_den = dense_in(c3_emb)\n",
    "hidden_3 = dense_hidden(hidden_2_add)\n",
    "hidden_3_add = Add()([c3_den, hidden_3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c4_out = Dense(vocab_size, activation='softmax')(hidden_3_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model([c1_inp, c2_inp, c3_inp], c4_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "c3 (InputLayer)                  (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "c2 (InputLayer)                  (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "c1 (InputLayer)                  (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)          (None, 1, 42)         3570        c3[0][0]                         \n",
      "____________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)          (None, 1, 42)         3570        c2[0][0]                         \n",
      "____________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)          (None, 1, 42)         3570        c1[0][0]                         \n",
      "____________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)              (None, 42)            0           embedding_3[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 42)            0           embedding_2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 42)            0           embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 256)           11008       flatten_1[0][0]                  \n",
      "                                                                   flatten_2[0][0]                  \n",
      "                                                                   flatten_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 256)           65792       dense_1[0][0]                    \n",
      "                                                                   add_1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "add_1 (Add)                      (None, 256)           0           dense_1[1][0]                    \n",
      "                                                                   dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "add_2 (Add)                      (None, 256)           0           dense_1[2][0]                    \n",
      "                                                                   dense_2[1][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 85)            21845       add_2[0][0]                      \n",
      "====================================================================================================\n",
      "Total params: 109,355\n",
      "Trainable params: 109,355\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "200297/200297 [==============================] - 25s - loss: 2.3976    \n",
      "Epoch 2/3\n",
      "200297/200297 [==============================] - 23s - loss: 2.2589    \n",
      "Epoch 3/3\n",
      "200297/200297 [==============================] - 24s - loss: 2.2062    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11671fe80>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([x1, x2, x3], y, batch_size=64, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = [char_to_idx[c] for c in inp]\n",
    "    arrs = [np.array([i]) for i in idxs]\n",
    "    p = model.predict(arrs)\n",
    "    i = np.argmax(p)\n",
    "    return chars[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'l'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('phi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next(' th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next(' an')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## first RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clen = 8\n",
    "\n",
    "c_in_data = [[idx[i+n] for i in range(0, len(idx)-clen-1, clen)]\n",
    "             for n in range(clen)]\n",
    "c_out_data = [idx[i+8] for i in range(0, len(idx)-clen-1, clen)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xs = [np.array(dat) for dat in c_in_data]\n",
    "y = np.array(c_out_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def embeding_input(name, n_in, n_out):\n",
    "    inp = Input((1,), dtype='int64', name=name+'_in')\n",
    "    emb = Embedding(n_in, n_out, input_length=1, name=name+'_emb')(inp)\n",
    "    return inp, Flatten()(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_fac = 42\n",
    "\n",
    "c_inps, c_embs = zip(*[embeding_input('c'+str(n), vocab_size, n_fac) for n in range(clen)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dense_hidden的初始化方式是identity（单位矩阵），这样能保证在初始化时，这个dense层不会影响通过的数据（A*I=A）\n",
    "\n",
    "原因参考Hinton的论文A Simple Way to Initialize Recurrent Networks of Rectified Linear Units：https://arxiv.org/abs/1504.00941"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden = 256\n",
    "\n",
    "dense_in = Dense(n_hidden, activation='relu')\n",
    "dense_hidden = Dense(n_hidden, activation='relu', kernel_initializer='identity')\n",
    "dense_out = Dense(vocab_size, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_dens = [dense_in(c_emb) for c_emb in c_embs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_add = c_dens[0]\n",
    "\n",
    "for n in range(1, clen):\n",
    "    c_hidden = dense_hidden(c_add)\n",
    "    c_add = Add()([c_hidden, c_dens[n]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_out = dense_out(c_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(list(c_inps), c_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "c0_in (InputLayer)               (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "c0_emb (Embedding)               (None, 1, 42)         3570        c0_in[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "c1_in (InputLayer)               (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)             (None, 42)            0           c0_emb[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "c1_emb (Embedding)               (None, 1, 42)         3570        c1_in[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "dense_7 (Dense)                  (None, 256)           11008       flatten_12[0][0]                 \n",
      "                                                                   flatten_13[0][0]                 \n",
      "                                                                   flatten_14[0][0]                 \n",
      "                                                                   flatten_15[0][0]                 \n",
      "                                                                   flatten_16[0][0]                 \n",
      "                                                                   flatten_17[0][0]                 \n",
      "                                                                   flatten_18[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)             (None, 42)            0           c1_emb[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "c2_in (InputLayer)               (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_8 (Dense)                  (None, 256)           65792       dense_7[0][0]                    \n",
      "                                                                   add_10[0][0]                     \n",
      "                                                                   add_11[0][0]                     \n",
      "                                                                   add_12[0][0]                     \n",
      "                                                                   add_13[0][0]                     \n",
      "                                                                   add_14[0][0]                     \n",
      "                                                                   add_15[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "c2_emb (Embedding)               (None, 1, 42)         3570        c2_in[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "add_10 (Add)                     (None, 256)           0           dense_8[0][0]                    \n",
      "                                                                   dense_7[1][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "flatten_14 (Flatten)             (None, 42)            0           c2_emb[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "c3_in (InputLayer)               (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "c3_emb (Embedding)               (None, 1, 42)         3570        c3_in[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "add_11 (Add)                     (None, 256)           0           dense_8[1][0]                    \n",
      "                                                                   dense_7[2][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "flatten_15 (Flatten)             (None, 42)            0           c3_emb[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "c4_in (InputLayer)               (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "c4_emb (Embedding)               (None, 1, 42)         3570        c4_in[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "add_12 (Add)                     (None, 256)           0           dense_8[2][0]                    \n",
      "                                                                   dense_7[3][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "flatten_16 (Flatten)             (None, 42)            0           c4_emb[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "c5_in (InputLayer)               (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "c5_emb (Embedding)               (None, 1, 42)         3570        c5_in[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "add_13 (Add)                     (None, 256)           0           dense_8[3][0]                    \n",
      "                                                                   dense_7[4][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "flatten_17 (Flatten)             (None, 42)            0           c5_emb[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "c6_in (InputLayer)               (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "c6_emb (Embedding)               (None, 1, 42)         3570        c6_in[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "add_14 (Add)                     (None, 256)           0           dense_8[4][0]                    \n",
      "                                                                   dense_7[5][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "flatten_18 (Flatten)             (None, 42)            0           c6_emb[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "add_15 (Add)                     (None, 256)           0           dense_8[5][0]                    \n",
      "                                                                   dense_7[6][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_9 (Dense)                  (None, 85)            21845       dense_8[6][0]                    \n",
      "====================================================================================================\n",
      "Total params: 123,635\n",
      "Trainable params: 123,635\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(Adam(), 'sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "75111/75111 [==============================] - 35s - loss: 2.5196    \n",
      "Epoch 2/3\n",
      "75111/75111 [==============================] - 33s - loss: 2.4561    \n",
      "Epoch 3/3\n",
      "75111/75111 [==============================] - 34s - loss: 2.4045    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x116b5fe10>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xs, y, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('for thos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('part of ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('queens a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## first RNN with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_fac = 42\n",
    "n_hidden = 256\n",
    "clen = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 8, 42)             3570      \n",
      "_________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)     (None, 256)               76544     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 85)                21845     \n",
      "=================================================================\n",
      "Total params: 101,959\n",
      "Trainable params: 101,959\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(vocab_size, n_fac, input_length=clen),\n",
    "    SimpleRNN(n_hidden, activation='relu', recurrent_initializer='identity'),\n",
    "    Dense(vocab_size, activation='softmax'),\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(Adam(), 'sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "75111/75111 [==============================] - 39s - loss: 2.6614    \n",
      "Epoch 2/5\n",
      "75111/75111 [==============================] - 38s - loss: 2.1609    \n",
      "Epoch 3/5\n",
      "75111/75111 [==============================] - 38s - loss: 1.9578    \n",
      "Epoch 4/5\n",
      "75111/75111 [==============================] - 32s - loss: 1.8220    \n",
      "Epoch 5/5\n",
      "75111/75111 [==============================] - 36s - loss: 1.7284    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11c6e04a8>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.concatenate(xs, axis=1), y, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next(s):\n",
    "    idxs = [char_to_idx[c] for c in s]\n",
    "    pred = model.predict(np.array([idxs]))\n",
    "    pred_idx = pred.argmax(axis=1)[0]\n",
    "    return idx_to_char[pred_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('this is ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('part of ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('queens a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Return Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clen = 8\n",
    "\n",
    "c_in_data = [[idx[i+n] for i in range(0, len(idx)-clen-1, clen)]\n",
    "             for n in range(clen)]\n",
    "c_out_data = [[idx[i+n+1] for i in range(0, len(idx)-clen-1, clen)]\n",
    "             for n in range(clen)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xs = [np.array(dat) for dat in c_in_data]\n",
    "ys = [np.array(dat) for dat in c_out_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[40,  1, 33,  2, 72],\n",
       "       [42,  1, 38, 44,  2],\n",
       "       [29, 43, 31, 71, 54],\n",
       "       [30, 45,  2, 74,  2],\n",
       "       [25, 40, 73, 73, 76],\n",
       "       [27, 40, 61, 61, 68],\n",
       "       [29, 39, 54,  2, 66],\n",
       "       [ 1, 43, 73, 62, 54]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(xs)[:, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[42,  1, 38, 44,  2],\n",
       "       [29, 43, 31, 71, 54],\n",
       "       [30, 45,  2, 74,  2],\n",
       "       [25, 40, 73, 73, 76],\n",
       "       [27, 40, 61, 61, 68],\n",
       "       [29, 39, 54,  2, 66],\n",
       "       [ 1, 43, 73, 62, 54],\n",
       "       [ 1, 33,  2, 72, 67]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(ys)[:, :5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def embeding_input(name, n_in, n_out):\n",
    "    inp = Input((1,), dtype='int64', name=name+'_in')\n",
    "    emb = Embedding(n_in, n_out, input_length=1, name=name+'_emb')(inp)\n",
    "    return inp, Flatten()(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_fac = 42\n",
    "\n",
    "c_inps, c_embs = zip(*[embeding_input('c'+str(n), vocab_size, n_fac) for n in range(clen)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_hidden = 256\n",
    "\n",
    "dense_in = Dense(n_hidden, activation='relu')\n",
    "dense_hidden = Dense(n_hidden, activation='relu', kernel_initializer='identity')\n",
    "dense_out = Dense(vocab_size, activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_dens = [dense_in(c_emb) for c_emb in c_embs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c_outs = []\n",
    "\n",
    "# 添加一个空的input(输入全为0)\n",
    "inp_zeros = Input((n_fac, ), name='zeros')\n",
    "c_add = dense_in(inp_zeros)\n",
    "for n in range(clen):\n",
    "    c_hidden = dense_hidden(c_add)\n",
    "    c_add = Add()([c_hidden, c_dens[n]])\n",
    "    c_outs.append(dense_out(c_add))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model([inp_zeros]+list(c_inps), c_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "c0_in (InputLayer)               (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "zeros (InputLayer)               (None, 42)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "c0_emb (Embedding)               (None, 1, 42)         3570        c0_in[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "dense_12 (Dense)                 (None, 256)           11008       flatten_20[0][0]                 \n",
      "                                                                   flatten_21[0][0]                 \n",
      "                                                                   flatten_22[0][0]                 \n",
      "                                                                   flatten_23[0][0]                 \n",
      "                                                                   flatten_24[0][0]                 \n",
      "                                                                   flatten_25[0][0]                 \n",
      "                                                                   flatten_26[0][0]                 \n",
      "                                                                   flatten_27[0][0]                 \n",
      "                                                                   zeros[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "flatten_20 (Flatten)             (None, 42)            0           c0_emb[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "c1_in (InputLayer)               (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_13 (Dense)                 (None, 256)           65792       dense_12[9][0]                   \n",
      "                                                                   add_25[0][0]                     \n",
      "                                                                   add_26[0][0]                     \n",
      "                                                                   add_27[0][0]                     \n",
      "                                                                   add_28[0][0]                     \n",
      "                                                                   add_29[0][0]                     \n",
      "                                                                   add_30[0][0]                     \n",
      "                                                                   add_31[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "c1_emb (Embedding)               (None, 1, 42)         3570        c1_in[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "add_25 (Add)                     (None, 256)           0           dense_13[8][0]                   \n",
      "                                                                   dense_12[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_21 (Flatten)             (None, 42)            0           c1_emb[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "c2_in (InputLayer)               (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "c2_emb (Embedding)               (None, 1, 42)         3570        c2_in[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "add_26 (Add)                     (None, 256)           0           dense_13[9][0]                   \n",
      "                                                                   dense_12[1][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_22 (Flatten)             (None, 42)            0           c2_emb[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "c3_in (InputLayer)               (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "c3_emb (Embedding)               (None, 1, 42)         3570        c3_in[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "add_27 (Add)                     (None, 256)           0           dense_13[10][0]                  \n",
      "                                                                   dense_12[2][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_23 (Flatten)             (None, 42)            0           c3_emb[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "c4_in (InputLayer)               (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "c4_emb (Embedding)               (None, 1, 42)         3570        c4_in[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "add_28 (Add)                     (None, 256)           0           dense_13[11][0]                  \n",
      "                                                                   dense_12[3][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_24 (Flatten)             (None, 42)            0           c4_emb[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "c5_in (InputLayer)               (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "c5_emb (Embedding)               (None, 1, 42)         3570        c5_in[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "add_29 (Add)                     (None, 256)           0           dense_13[12][0]                  \n",
      "                                                                   dense_12[4][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_25 (Flatten)             (None, 42)            0           c5_emb[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "c6_in (InputLayer)               (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "c6_emb (Embedding)               (None, 1, 42)         3570        c6_in[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "add_30 (Add)                     (None, 256)           0           dense_13[13][0]                  \n",
      "                                                                   dense_12[5][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_26 (Flatten)             (None, 42)            0           c6_emb[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "c7_in (InputLayer)               (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "c7_emb (Embedding)               (None, 1, 42)         3570        c7_in[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "add_31 (Add)                     (None, 256)           0           dense_13[14][0]                  \n",
      "                                                                   dense_12[6][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "flatten_27 (Flatten)             (None, 42)            0           c7_emb[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "add_32 (Add)                     (None, 256)           0           dense_13[15][0]                  \n",
      "                                                                   dense_12[7][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_14 (Dense)                 (None, 85)            21845       add_25[0][0]                     \n",
      "                                                                   add_26[0][0]                     \n",
      "                                                                   add_27[0][0]                     \n",
      "                                                                   add_28[0][0]                     \n",
      "                                                                   add_29[0][0]                     \n",
      "                                                                   add_30[0][0]                     \n",
      "                                                                   add_31[0][0]                     \n",
      "                                                                   add_32[0][0]                     \n",
      "====================================================================================================\n",
      "Total params: 127,205\n",
      "Trainable params: 127,205\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(Adam(), 'sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75111, 42)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros = np.zeros((len(xs[0]), n_fac))\n",
    "zeros.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "75111/75111 [==============================] - 52s - loss: 19.4717 - dense_14_loss_1: 2.6323 - dense_14_loss_2: 2.4933 - dense_14_loss_3: 2.4249 - dense_14_loss_4: 2.3949 - dense_14_loss_5: 2.3820 - dense_14_loss_6: 2.3812 - dense_14_loss_7: 2.3880 - dense_14_loss_8: 2.3751    \n",
      "Epoch 2/3\n",
      "75111/75111 [==============================] - 57s - loss: 17.5433 - dense_14_loss_1: 2.5067 - dense_14_loss_2: 2.3476 - dense_14_loss_3: 2.1953 - dense_14_loss_4: 2.1272 - dense_14_loss_5: 2.0962 - dense_14_loss_6: 2.0912 - dense_14_loss_7: 2.0989 - dense_14_loss_8: 2.0803    \n",
      "Epoch 3/3\n",
      "75111/75111 [==============================] - 52s - loss: 16.9984 - dense_14_loss_1: 2.4946 - dense_14_loss_2: 2.3303 - dense_14_loss_3: 2.1481 - dense_14_loss_4: 2.0504 - dense_14_loss_5: 2.0028 - dense_14_loss_6: 1.9938 - dense_14_loss_7: 1.9978 - dense_14_loss_8: 1.9806     ETA: 0s - loss: 17.0003 - dense_14_loss_1: 2.4951 - dense_14_loss_2: 2.3304 - dense_14_loss_3: 2.1472 - dense_14_loss_4: 2.0502 - dense_14_loss_5: 2.0037 - dense_14_loss_6: 1.9943 - dense_14_loss_7: 1.9982 - dense_14_\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x124be6278>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([zeros]+xs, ys, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_nexts(inp):\n",
    "    idxs = [char_to_idx[c] for c in inp]\n",
    "    arrs = [np.array(i)[np.newaxis] for i in idxs]\n",
    "    p = model.predict([np.zeros(n_fac)[np.newaxis,:]] + arrs)\n",
    "    print(list(inp))\n",
    "    return [chars[np.argmax(o)] for o in p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 't', 'h', 'i', 's', ' ', 'i', 's']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['t', 'h', 'e', 't', ' ', 'c', 'n', ' ']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nexts(' this is')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 'p', 'a', 'r', 't', ' ', 'o', 'f']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['t', 'o', 'i', 'i', 'i', 'o', 'f', ' ']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nexts(' part of')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence model with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_fac = 42\n",
    "n_hidden = 256\n",
    "clen = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "理论上，Dense层是会compile错误的，因为输入有(None, 8, 256)，Dense只支持(None, x)的形式\n",
    "\n",
    "而且TimeDistributed(Dense())和Dense()跑出来效果貌似一样\n",
    "\n",
    "有待研究（TODO）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Embedding(vocab_size, n_fac, input_length=clen),\n",
    "    SimpleRNN(n_hidden, activation='relu', recurrent_initializer='identity', return_sequences=True),\n",
    "#     Dense(vocab_size, activation='softmax'),\n",
    "    TimeDistributed(Dense(vocab_size, activation='softmax')),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 8, 42)             3570      \n",
      "_________________________________________________________________\n",
      "simple_rnn_5 (SimpleRNN)     (None, 8, 256)            76544     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 8, 85)             21845     \n",
      "=================================================================\n",
      "Total params: 101,959\n",
      "Trainable params: 101,959\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(Adam(), 'sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8, 75111), (8, 75111, 1))"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(xs).shape, np.array(ys).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((75111, 8), (75111, 8, 1))"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_rnn = np.stack(xs, axis=1)\n",
    "y_rnn = np.stack(ys, axis=1)\n",
    "x_rnn.shape, y_rnn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "75111/75111 [==============================] - 55s - loss: 2.2979    \n",
      "Epoch 2/3\n",
      "75111/75111 [==============================] - 54s - loss: 1.9234    \n",
      "Epoch 3/3\n",
      "75111/75111 [==============================] - 53s - loss: 1.8309    - ETA: 2s \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x127723e10>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_rnn, y_rnn, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_nexts_keras(inp):\n",
    "    idxs = [char_to_idx[c] for c in inp]\n",
    "    arr = np.array(idxs)[np.newaxis,:]\n",
    "    print(idxs)\n",
    "    p = model.predict(arr)[0]\n",
    "    print(list(inp))\n",
    "    return [chars[np.argmax(o)] for o in p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 73, 61, 62, 72, 2, 62, 72]\n",
      "[' ', 't', 'h', 'i', 's', ' ', 'i', 's']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['t', 'h', 'e', 's', ' ', 'p', 'n', ' ']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_nexts_keras(' this is')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_res = model.predict(np.array([[2, 73, 61, 62, 72, 2, 62, 72]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  4.28957581e-09,   2.27964600e-03,   8.09430424e-03,\n",
       "           7.61173396e-06,   1.00660827e-02,   1.56000067e-04,\n",
       "           4.40317160e-03,   9.32861269e-07,   1.97696390e-05,\n",
       "           1.23181680e-05],\n",
       "        [  7.34072247e-10,   8.70438998e-06,   1.79276722e-05,\n",
       "           2.12791838e-05,   1.34460433e-05,   7.82672287e-05,\n",
       "           1.65134750e-09,   2.39030828e-06,   1.43394445e-05,\n",
       "           1.85931719e-06],\n",
       "        [  5.62891400e-10,   2.80850509e-05,   1.79209863e-04,\n",
       "           1.05162171e-05,   1.24897224e-05,   1.39619697e-05,\n",
       "           3.78998832e-10,   4.50970265e-06,   4.74963963e-05,\n",
       "           1.28726169e-05],\n",
       "        [  3.80432977e-11,   9.33941578e-07,   8.90961292e-06,\n",
       "           5.22022283e-08,   2.80523892e-07,   1.11163665e-07,\n",
       "           1.11883046e-11,   7.10334191e-08,   2.68941199e-06,\n",
       "           2.67958103e-06],\n",
       "        [  1.12557341e-08,   1.41721725e-01,   7.61174262e-01,\n",
       "           6.65230618e-04,   4.90249135e-04,   2.97799088e-05,\n",
       "           3.33891609e-10,   2.95311445e-04,   2.89304312e-02,\n",
       "           1.10824103e-03],\n",
       "        [  1.00299452e-07,   4.69386287e-05,   1.07214975e-04,\n",
       "           2.65362251e-05,   8.23328178e-03,   1.18000768e-04,\n",
       "           1.72407553e-03,   5.93679033e-06,   2.70925666e-05,\n",
       "           4.77009540e-04],\n",
       "        [  4.99521147e-10,   2.82206220e-05,   1.69679942e-03,\n",
       "           9.11268330e-07,   3.02738135e-06,   1.20214295e-07,\n",
       "           2.18308438e-09,   6.58977967e-07,   2.49690602e-05,\n",
       "           5.40399787e-06],\n",
       "        [  6.74754190e-08,   8.08828101e-02,   7.86528111e-01,\n",
       "           1.15372136e-03,   1.83400779e-03,   2.55796240e-05,\n",
       "           1.64228723e-07,   6.56545220e-04,   2.41314564e-02,\n",
       "           4.94125672e-03]]], dtype=float32)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_res[:, :, :10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (64, 8, 42)               3570      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (64, 8, 42)               168       \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (64, 8, 256)              306176    \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (64, 8, 85)               21845     \n",
      "=================================================================\n",
      "Total params: 331,759\n",
      "Trainable params: 331,675\n",
      "Non-trainable params: 84\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential([\n",
    "        Embedding(vocab_size, n_fac, input_length=clen, batch_input_shape=(64,8)),\n",
    "        BatchNormalization(),\n",
    "        LSTM(n_hidden, return_sequences=True, stateful=True),\n",
    "        TimeDistributed(Dense(vocab_size, activation='softmax')),\n",
    "    ])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
